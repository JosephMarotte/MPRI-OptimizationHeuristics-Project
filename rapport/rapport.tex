\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
%\usepackage{amsfonts}
%\usepackage{geometry}
%\usepackage{graphicx}
%\usepackage{url}
%\usepackage{amsthm}
%\usepackage{float}
\usepackage{mathpazo}
\usepackage[]{algorithm2e}
\usepackage{csvsimple}
\usepackage{graphics}
\usepackage{adjustbox}

\usepackage
[
a4paper,
left=1.5cm,
right=2.5cm,
top=1.5cm,
bottom=2cm
]{geometry}

\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem*{definition}{Definition}
\newtheorem*{notation}{Notation}
\newtheorem*{example}{Example}
\newtheorem*{problem}{Problem}
\theoremstyle{plain}
\newtheorem*{lemma}{Lemma}
\newtheorem*{theorem}{Theorem}
\newtheorem*{proposition}{Proposition}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

% Maths operators 
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\Sep}{Sep}
\DeclareMathOperator{\Conv}{Conv}

% My commands
\newcommand{\myequiv}[1]{\underset{#1}{\sim}}
\newcommand\mydef{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily def}}}{=}}}

\title{Mastermind with $n$ colors}
\author{}
\date{}
\begin{document}

\maketitle

\subsection{Problem setting}

We consider an array of length $N$, each cell contains a number in $\{0, 1, \ldots, $N-1$ \}$.

We can compare another array with this array, the integer returned is the number of equal cells.

The purpose of the algorithms we study is to find this array using a minimum number of comparison with it.

\subsection{Exhaustive-Search}
\subsubsection{Algorithm}

The first algorithm is an exhaustive search

\begin{algorithm}[H]
	\caption{Exhaustive Search}
	\While{F(S) != N}{
		$S \leftarrow $ next array;\\
		Evaluate $F(S)$;
	}
\end{algorithm}

\subsubsection{Result}

\maxsizebox{\textwidth}{\paperheight}{\csvautotabular{exploit_performance_value/exhaustive_search.csv}}

The complexity is roughly what we expect : $\Theta(N^N)$.

\subsection{Erdos-Renyi}

\subsubsection{Algorithm}
\begin{algorithm}[H]
	\Begin{
		Pick a Set S of random array in $\{0, ..., N-1\}^N$ to Evaluate.\\
		\ForEach{A in S}{compute F(A)}
		Create an empty set of possible solution S'
		\ForEach{Possible Array A'}{
			\ForEach{A in S}{
				\If{distance(A, A') != F(A)}{A' can't be solution\\ Continue to next iteration step}
			}
			Add A' to S'
		}
	}
	\caption{Erdos Renyi Algorithm}
\end{algorithm}

With a big enough value of $|S|$ (see Erdos-Renyi study), we have $|S'| = 1$ with high probability.

\subsubsection{Result}

\maxsizebox{\textwidth}{\paperheight}{\csvautotabular{exploit_performance_value/erdos_renyi.csv}}

We try to adapt the Erdos-Renyi algorithm to $N$ colors.
The algorithm yields good result in term of number of call to the comparison function but the overall time needed is in $O(N^N)$.

\subsection{Random Local Search}
\subsubsection{Algorithm}
\begin{algorithm}[H]
	\caption{Random Local Search}
	$S \leftarrow$ random array
	\While{F(S) != N}{
		$i \leftarrow$ randint(0, N-1)\\
		$S' \leftarrow S$\\
		$S'[i] \leftarrow step()$\\
		\If{F(S') > F(S)}{$S \leftarrow S'$}
	}
\end{algorithm}
\subsubsection{Result}

\maxsizebox{\textwidth}{\paperheight}{\csvautotabular{exploit_performance_value/RLS_cleaned.csv}}

The experimental results seems to show that the overall complexity is in $N \cdot N \cdot log(N)$

\section{Evolutionary Algorithm}
We now study evolutionary algorithm.
The step function used for all our algorithm consist of picking a random new color for a cell.
\subsection{(1+1) Evolution Algorithm}
\subsubsection{Algorithm}
\begin{algorithm}[H]
	\caption{(1+1)EA}
	$S \leftarrow$ random array\\
	\While{F(S) != N}{
		$S' \leftarrow S$\\
		\For{$i = 0;\ i < N;\ i++$}{
			\If{random() <= mutation\_rate}{
				$S'[i] \leftarrow step()$\\
			}
		}
		\If{F(S') > F(S)}{$S \leftarrow S'$}
	}
\end{algorithm}


\subsubsection{Result}

\maxsizebox{\textwidth}{\paperheight}{\csvautotabular{exploit_performance_value/EA_mu_lambda.csv}}

\subsection{$(\mu +\lambda)$Genetic Algorithm}

\begin{algorithm}[H]
	\caption{$(\mu+\lambda)$GA}
	$S \leftarrow$ Set of $\mu$ random array\\
	\While{max(F(S)) != N}{
		$S' \leftarrow$ empty Set\\
		\For{$i = 0;\ i < \lambda;\ i++$}{
			$A \leftarrow$ majority\_vote(S, k)\\
			\For{$j = 0;\ j < N;\ j++$}{
				\If{random() <= mutation\_rate}{
					$A[i] \leftarrow step()$\\
				}
				Add A to S'
			}
			$S \leftarrow$ Elitist\_Selection($S, S'$)
		}
	}
\end{algorithm}

\subsubsection{Result}

\maxsizebox{\textwidth}{\paperheight}{    \csvautotabular{exploit_performance_value/GA_mu_lambda.csv}}

Having a bigger value for $\mu$ and $\lambda$ doesn't seems to yield better result. Maybe because the mutation rate was set to be equals to $\frac{1}{lambda}$.

Value of $\mu$ and $\lambda$ are not easy to choose. In some case, I believe having a smaller value for $\mu$ speed up the algorithm but may makes good assignment of a cell being forgotten (for example, 1 good cell change to be wrong, but 2 wrong changes to be good). Having a larger value for $\mu$ means older value are not immediately deleted, so in the same case, the information of the good cell which was changed may be retrieved, but it means in some case only not so good will be used in the majority vote of A and the generated offspring may not be the best because because of that.

I believe the $1 + (\lambda, \lambda)GA$ we present now get the best of both worlds.

\subsection{$1 + (\lambda, \lambda)GA$}
Lastly we tried to adapt the $1 + (\lambda, \lambda)GA$ of the "Optimal Parameter Choices Through Self-Adjustment: Applying the 1/5-th Rule in Discrete Settings" to our case.

\subsubsection{Algorithm}
\begin{algorithm}[H]
	\caption{$1 + (\lambda, \lambda)$GA}
	$S \leftarrow$ random array\\
	\While{F(S) != N}{
		\textbf{Mutation phase}\\
		\Begin{
			\For{$i = 0;\ i < \lambda;\ i++$}{
				$X_i \leftarrow S$
				\For{$j = 0;\ j < N;\ j++$}{
					\If{random() <= mutation\_rate}{
						$X_i[j] \leftarrow step()$
					}
				}
				Compute(F($X_i$))\\
			}
			$X \leftarrow X_i$ such that $f(X)$ is maximized\\
		}
		\textbf{Crossover phase}\\
		\Begin{
			\For{$i = 0;\ i < \lambda;\ i++$}{
				\For{$j = 0;\ j < N;\ j++$}{
					$Y_i[j] \leftarrow cross_{c}(S, X)$
				}
				Compute(F($Y_i$))\\
			}
			$Y \leftarrow Y_i$ such that $f(Y_i)$ is maximized\\
		}
		\textbf{Optional Auto Adjustment Rate}
		\Begin{
			\If{F(Y) > F(S)}{$\lambda \leftarrow$ max($\lambda / F, 1)$}
			\Else{$\lambda \leftarrow$ min($\lambda F^{1/4}, N$)}\\
		}
		
		\If{F(Y) > F(S)}{S \leftarrow Y\\}
	}
\end{algorithm}

Where $F$ is the update strength, $c$ is the crossover rate and is equals to $\frac{1}{\lambda}$, and the $mutation\_rate$ is equals to $\frac{\lambda}{N}$.

The function $cross_c(x, y)$ output an array $z$ and $z[i] = x[i]$ with probability $c$ and $z[i] = y[i]$ otherwise.

In the adaptive version, $c$ and $mutate\_rate$ change with the value of $\lambda$. In the case of the non-adaptive version, they remains the same (the initial value).

\subsubsection{Result}

\textbf{Non-adaptive version}

\maxsizebox{\textwidth}{\paperheight}{\csvautotabular{exploit_performance_value/GA_1_plus_mu_lambda.csv}}

\textbf{Adaptive version}

\maxsizebox{\textwidth}{\paperheight}{\csvautotabular{exploit_performance_value/GA_1_plus_mu_lambda_adaptive.csv}}

In the case of the non-adaptive version, having a large $\lambda$ doesn't seems to yield significant better results than having a smaller one (keep in mind the number of experiment is equals to 15).

The adaptive case have better results than the other case. I believe the reason is that at all stages of the algorithm, the value of the $\lambda$ is changed to have step with better performances: a small lambda at the early stage of the algorithm because when most of the cells aren't equals, changing only a few cells means one of them is probably false and hence we have good chance of finding the real value of a cell.

In the late stage of the algorithm, I believe the value of the lambda increase, hence we have more mutation and more offspring. Among these offspring, the best offspring $X$ is probably a poor choice in itself (because a lot of correct values of $S$ where mutated) and the cross function will have a small value for $c$ so we are almost ensured to keep the good values of the initial $S$ and only change the new one found by $X$.

\section{Conclusion}
To conclude for all the evolutionary algorithm the complexity seems to remains in $O(N \cdot N \cdot log(N))$, only the adaptive version have experimental results close to the random local search.

\end{document}
