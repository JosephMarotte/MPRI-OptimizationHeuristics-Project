Remarque : j'ai l'impression que pour toutes les méthodes vraiment heuristiques (typiquement RLS et (1+1)-EA) on perd un facteur n. À mon avis tous les trucs locaux vont être très mauvais par rapport aux méthodes « algébriques ».

- Coder les trucs débiles genre exhaustif, complètement random, RLS, (1+1)-EA, (mu+lambda)-EA
- Faire les courbes (+ lire les slides sur les différentes manières d'étudier les complexités black box)
- Traiter le n log log n https://arxiv.org/pdf/1207.0773.pdf + voir version non adaptative (+ lien avec Erdös-Renyi-like)
- 1+(lambda,lambda) + essayer d'étendre https://arxiv.org/pdf/1504.03212.pdf
- Le Erdös-Renyi-like (je pense que c'est du n log n, c'est en gros l'algo pour le régime avec n^{1-eps} couleurs mentionné dans l'article sur le n log log n) + éventuellement regarder les autres n log n antérieurs cités (les constantes ont l'air d'être optimisées à la main donc ça a l'air chiant)
- Sélection de paramètres : sur 1+(lambda,lambda) ou (mu+lambda)
    - bandit multi-armé, UCB, blabla (à mon avis dur de prouver des trucs dessus)
    - paramètres auto-ajustants (cf. plus haut)
    - dépendant du temps (recuit simulé suspect ici car pas de minima locaux non globaux)
    - faire une autre heuristique pour ajuster les paramètres
    - landscape-aware, ML (à voir)
- Regarder les causes du gap pour k=n (normalement ça devrait être plus dur car il y a un gap non résolu n/n log log n)
- Faire les bornes inférieures précises pour (1+1)-EA (trouver la ref pour p=c/n sur OneMax)
