import pathlib
import pandas as pd


def clean_data(in_csv_file, out_csv_file, in_column, out_column):
    data = pd.read_csv(in_csv_file, names=in_column, header=None, sep=" ")
    data = data.groupby(in_column[:-1])

    data = data.agg({'nb_call': [lambda x: x.quantile(0.02),
                                 lambda x: x.quantile(0.25),
                                 lambda x: x.quantile(0.50),
                                 lambda x: x.quantile(0.75),
                                 lambda x: x.quantile(0.98),
                                 'mean',
                                 'std',
                                 'count']})

    data.columns = list(map(''.join, data.columns.values))
    data.columns = out_column
    data = data.reset_index()
    data.to_csv(out_csv_file)
    return data


column_added = ["per 0.02", "per 0.25", "per 0.5", "per 0.75", "per 0.98", "mean", "std dev", "count"]
result_dir = str(pathlib.Path(__file__).parent.parent.absolute()) + "/results/"

# RLS
path_to_result_dir = result_dir + "RLS_UNIFORM_MUTATION.csv"
data = clean_data(path_to_result_dir,
                  "RLS_cleaned.csv",
                  ["array_size", "nb_color", "nb_call"],
                  column_added)
data.insert(0, 'algo', 'RLS')

# # EA_MU_LAMBDA
path_to_result_dir = result_dir + "EA_mu_lambda.csv"
new_data = clean_data(path_to_result_dir,
           "EA_mu_lambda.csv",
           ["array_size", "nb_color", "mu", "lambda", "mutation_rate", "nb_call"],
           column_added)
new_data.insert(0, 'algo', 'EA_MU_LAMBDA')
data = pd.concat((data, new_data))

# GA_MU_PLUS_LAMBDA
path_to_result_dir = result_dir + "GA_mu_lambda.csv"
new_data = clean_data(path_to_result_dir,
           "GA_mu_lambda.csv",
           ["array_size", "nb_color", "mu", "lambda", "mutation_rate", "nb_call"],
           column_added)
new_data.insert(0, 'algo', 'GA_MU_LAMBDA')
data = pd.concat((data, new_data))

# GA_ONE_PLUS_MU_LAMBDA
path_to_result_dir = result_dir + "GA_1_plus_mu_lambda.csv"
new_data = clean_data(path_to_result_dir,
           "GA_1_plus_mu_lambda.csv",
           ["array_size", "nb_color", "lambda", "mutation_rate", "crossover_probability", "nb_call"],
           column_added)
new_data.insert(0, 'algo', 'GA_1_PLUS_MU_LAMBDA')
data = pd.concat((data, new_data))

# GA_ONE_PLUS_MU_LAMBDA_ADAPTIVE
path_to_result_dir = result_dir + "GA_1_plus_mu_lambda_adaptive.csv"
new_data = clean_data(path_to_result_dir,
           "GA_1_plus_mu_lambda_adaptive.csv",
           ["array_size", "nb_color", "update_strength", "nb_call"],
           column_added)
new_data.insert(0, 'algo', 'GA_1_PLUS_MU_LAMBDA_ADAPTIVE')
data = pd.concat((data, new_data))

# EXHAUSTIVE_SEARCH
path_to_result_dir = result_dir + "exhaustive_search.csv"
new_data = clean_data(path_to_result_dir,
           "exhaustive_search.csv",
           ["array_size", "nb_color", "nb_call"],
           column_added)
new_data.insert(0, 'algo', 'EXHAUSTIVE_SEARCH')
data = pd.concat((data, new_data))

# ERDOS RENYI
path_to_result_dir = result_dir + "erdos_renyi.csv"
new_data = clean_data(path_to_result_dir,
           "erdos_renyi.csv",
           ["array_size", "nb_color", "nb_call"],
           column_added)
new_data.insert(0, 'algo', 'ERDOS_RENYI')
data = pd.concat((data, new_data))
